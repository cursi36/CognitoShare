{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eed8c66",
   "metadata": {},
   "source": [
    "# Siamese Neural Networks for Face Recognition\n",
    "\n",
    "Train  a neural network to identify if inut pictures belong to same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338599bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2.cv2 as cv\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if (torch.cuda.device_count()):\n",
    "  print(torch.cuda.device_count())\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "\n",
    "#Assign cuda GPU located at location '0' to a variable\n",
    "  cuda0 = torch.device('cuda:0')\n",
    "else:\n",
    "  cuda0 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0488de",
   "metadata": {},
   "source": [
    "#### Define some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read images from files and converting to torch tensors\n",
    "def readImage(img_name,img_size = (224,224),plot=False):\n",
    "    n = cv.imread(img_name)\n",
    "    n = cv.resize(n, img_size, interpolation = cv.INTER_LINEAR)\n",
    "    n_torch = np.transpose(n, (2, 0, 1))\n",
    "    if plot:\n",
    "      plt.imshow(cv.cvtColor(n, cv.COLOR_BGR2RGB))\n",
    "      plt.show()\n",
    "\n",
    "    img_torch = torch.tensor(n_torch)\n",
    "    # img_torch = img_torch.float()\n",
    "    # img_torch = img_torch.reshape((1,n_torch.shape[0],n_torch.shape[1],n_torch.shape[2]))\n",
    "    # img_torch = img_torch/255\n",
    "\n",
    "    return n,img_torch\n",
    "\n",
    "#Function to generate pairs of images\n",
    "def generate_train_image_pairs(Names_list, Names_dict,pos_pairs,neg_pairs):    \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    N_names = len(Names_list)\n",
    "    for Name,index in zip(Names_list,tqdm(range(1,N_names))):\n",
    "        file_names = Names_dict[Name]\n",
    "\n",
    "        image = file_names[0]\n",
    "        print(\"**********************\")\n",
    "        print(\"imag base \", image)\n",
    "        _,base_img_torch = readImage(image,img_size,plot=False)\n",
    "        \n",
    "        #----------------#\n",
    "        #Get positive pairs (pairs from same person)\n",
    "\n",
    "        pos_indices = np.random.choice(len(file_names),pos_pairs)\n",
    "        for p in pos_indices:\n",
    "          pos_image = file_names[p]\n",
    "          print(\"pos image \", pos_image)\n",
    "          _,pos_img_torch = readImage(pos_image,img_size,plot=False)\n",
    "\n",
    "          pair_images.append((base_img_torch, pos_img_torch))\n",
    "          pair_labels.append(torch.ones(1,1))\n",
    "\n",
    "          #Augment positive pairs.\n",
    "          #This part just incrases the datasize with augmented pictures\n",
    "          for n_aug in range(3):\n",
    "            Aug_img_base = augmenter(base_img_torch)\n",
    "            Aug_img_pos = augmenter(pos_img_torch)\n",
    "            pair_images.append((Aug_img_base, Aug_img_pos))\n",
    "            pair_labels.append(torch.ones(1,1))\n",
    "\n",
    "            # plt.imshow(cv.cvtColor(np.transpose(Aug_img_base.numpy(),(1,2,0)), cv.COLOR_BGR2RGB))\n",
    "            # plt.imshow(cv.cvtColor(np.transpose(Aug_img_pos.numpy(),(1,2,0)), cv.COLOR_BGR2RGB))\n",
    "            # plt.show()\n",
    "            \n",
    "            \n",
    "        #----------------#\n",
    "        #Get negative pairs (pairs from different people)\n",
    "\n",
    "        neg_indices = np.where(Names_list != Name)[0]\n",
    "        neg_indices = np.random.choice(neg_indices,neg_pairs)\n",
    "\n",
    "        for n in neg_indices:\n",
    "          Name_neg = Names_list[n]\n",
    "          file_names = Names_dict[Name_neg]\n",
    "\n",
    "          neg_image = file_names[np.random.choice(len(file_names))]\n",
    "          print(\"neg  image \", neg_image)\n",
    "          _,neg_img_torch = readImage(neg_image,img_size,plot=False)\n",
    "\n",
    "          pair_images.append((base_img_torch, neg_img_torch))\n",
    "          pair_labels.append(0*torch.ones(1,1))\n",
    "\n",
    "         #AUgment Images\n",
    "          for n_aug in range(3):\n",
    "            Aug_img_base = augmenter(base_img_torch)\n",
    "            Aug_img_neg = augmenter(neg_img_torch)\n",
    "            pair_images.append((Aug_img_base, Aug_img_neg))\n",
    "            pair_labels.append(0*torch.ones(1,1))\n",
    "          \n",
    "    return pair_images, pair_labels\n",
    "\n",
    "#Function to divide the data into batches\n",
    "def GetBatches(pair_images,pair_labels,image_size,n_batches):\n",
    "  #**********To Do\n",
    "  batch_size = len(pair_images)//n_batches\n",
    "  print(\"batch size \", batch_size)\n",
    "\n",
    "  Batch_Images_1,Batch_Images_2,Batch_Labels = [], [],[]\n",
    "  for i in range(0,len(pair_images),batch_size):\n",
    "    images = pair_images[i:i+batch_size]\n",
    "    labels = pair_labels[i:i+batch_size]\n",
    "\n",
    "    Images_1 = torch.empty((0,3,image_size[0],image_size[1]))\n",
    "    Images_2 = torch.empty((0,3,image_size[0],image_size[1]))\n",
    "    Labels = torch.empty((0,1))\n",
    "\n",
    "    for image_pair,label in zip(images,labels):\n",
    "      image_pair_1 = image_pair[0].reshape(1,3,image_size[0],image_size[1])\n",
    "      image_pair_2 = image_pair[1].reshape(1,3,image_size[0],image_size[1])\n",
    "\n",
    "      Images_1 = torch.vstack((Images_1,image_pair_1))\n",
    "      Images_2 = torch.vstack((Images_2,image_pair_2))\n",
    "      Labels = torch.vstack((Labels,label.reshape(-1,1)))\n",
    "\n",
    "    Images_1 = Images_1.to(cuda0)\n",
    "    Images_2 = Images_2.to(cuda0)\n",
    "    Labels = Labels.to(cuda0)\n",
    "\n",
    "    # print(\"Batch Images shape \", Images_1.shape, \" Labels\",Labels.shape)\n",
    "\n",
    "    Batch_Images_1.append(Images_1)\n",
    "    Batch_Images_2.append(Images_2)\n",
    "    Batch_Labels.append(Labels)\n",
    "\n",
    "  return Batch_Images_1,Batch_Images_2,Batch_Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15bf2a2",
   "metadata": {},
   "source": [
    "#### Get the data from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_root = \"pubfig83/\" \n",
    "\n",
    "img_size = (90,90)\n",
    "augmenter = T.RandAugment()\n",
    "\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "#Get persons' names and images\n",
    "Names = dict() #dictionary of names and all files in subfolder\n",
    "subfolders = []\n",
    "el_counts = []\n",
    "Images_names = []\n",
    "for x in os.walk(folder_root):\n",
    "  name = x[0].split(\"/\")\n",
    "  filenames = glob.glob(x[0]+\"/*.jpg\")\n",
    "  if len(filenames):\n",
    "    Names[name[1]] = filenames\n",
    "    subfolders.append((x[0],filenames))\n",
    "    for filename in filenames:\n",
    "      Images_names.append(filename )\n",
    "\n",
    "Names_keys = list(Names.keys())\n",
    "\n",
    "#Generate the pairs of images\n",
    "#pos_pairs and neg_pairs set the number of pairs to generate for each person\n",
    "pair_images,pair_labels = generate_train_image_pairs(np.array(Names_keys),Names,pos_pairs=5,neg_pairs=5)\n",
    "\n",
    "\n",
    "#Split the data into training and test\n",
    "pair_images_train, pair_images_test, pair_labels_train, pair_labels_test = train_test_split(pair_images, pair_labels, test_size=0.15, random_state=42)\n",
    "print(\"Train data size\", len(pair_images_train))\n",
    "print(\"Test data size\", len(pair_images_test))\n",
    "\n",
    "#Split data into batches for training\n",
    "n_batches_train = 10\n",
    "Batch_Im_1,Batch_Im_2,Batch_Labels = GetBatches(pair_images_train,pair_labels_train,img_size,n_batches_train)\n",
    "Data_train = list(zip(Batch_Im_1,Batch_Im_2,Batch_Labels))\n",
    "\n",
    "#Single batch used for testing\n",
    "n_batches_test = 1\n",
    "Batch_Im_1,Batch_Im_2,Batch_Labels = GetBatches(pair_images_test,pair_labels_test,img_size,n_batches_test)\n",
    "Data_test = list(zip(Batch_Im_1,Batch_Im_2,Batch_Labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bf798",
   "metadata": {},
   "source": [
    "#### Define Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1614344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer block with maxpooling\n",
    "class ConvNetBlock(nn.Module):\n",
    "  def __init__(self,in_channel,out_channel,kernel_size,pool=True):\n",
    "    super(ConvNetBlock,self).__init__()\n",
    "\n",
    "    self.pool = pool\n",
    "    self.kernel_size = kernel_size\n",
    "    \n",
    "    self.batchNorm = torch.nn.BatchNorm2d(in_channel)\n",
    "\n",
    "    self.conv = torch.nn.Conv2d(in_channel, out_channel,kernel_size, stride=1)\n",
    "    self.act = nn.ReLU()\n",
    "    if pool:\n",
    "      self.maxpool = torch.nn.MaxPool2d(2)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.batchNorm(x)\n",
    "    x = self.conv(x)\n",
    "    x = self.act(x)\n",
    "\n",
    "    if self.pool:\n",
    "      x = self.maxpool(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#returns output figure size\n",
    "  def getImageSize(self,image_size):\n",
    "    h_in = image_size[0]\n",
    "    w_in = image_size[1]\n",
    "\n",
    "    h_out = int(h_in-self.kernel_size+1)\n",
    "    w_out = int(w_in-self.kernel_size+1)\n",
    "\n",
    "    if self.pool:\n",
    "      h_out = int((h_out-2)/2+1)\n",
    "      w_out = int((w_out-2)/2+1)\n",
    "\n",
    "    return (h_out,w_out)\n",
    "\n",
    "# Neywork for fetaure extraction\n",
    "class FeatureExtractNet(nn.Module):\n",
    "  def __init__(self,image_shape):\n",
    "    super(FeatureExtractNet,self).__init__()\n",
    "\n",
    "    self.conv = nn.ModuleList()\n",
    "    self.FC = nn.ModuleList()\n",
    "\n",
    "    self.conv.append(ConvNetBlock(3,16,5,True))\n",
    "    image_shape = self.conv[0].getImageSize(image_shape)\n",
    "\n",
    "    self.conv.append(ConvNetBlock(16,32,5,True))\n",
    "    image_shape = self.conv[1].getImageSize(image_shape)\n",
    "\n",
    "    self.conv.append(ConvNetBlock(32,64,3,True))\n",
    "    image_shape = self.conv[2].getImageSize(image_shape)\n",
    "\n",
    "    self.conv.append(ConvNetBlock(64,128,3,False))\n",
    "    image_shape = self.conv[3].getImageSize(image_shape)\n",
    "    \n",
    "    print(\"final image shape conv: \",image_shape)\n",
    "\n",
    "    in_dim = image_shape[0]*image_shape[1]*128\n",
    "    \n",
    "    # Fully connected layers\n",
    "    self.FC.append(torch.nn.Linear(in_dim,1000))\n",
    "    self.sigm = torch.nn.Sigmoid()\n",
    "    self.Out = torch.nn.Linear(1000,100)\n",
    "\n",
    "  def forward(self,x):\n",
    "\n",
    "    for conv in self.conv:\n",
    "      x = conv(x)\n",
    "\n",
    "    x = x.reshape(x.shape[0],-1)\n",
    "\n",
    "    for fc in self.FC:\n",
    "      x = fc(x)\n",
    "      x = self.sigm(x)\n",
    "\n",
    "    out = self.Out(x)\n",
    "\n",
    "    return out\n",
    "\n",
    "#This block computes the distance between feature vectors\n",
    "class DiffNet(nn.Module):\n",
    "  def __init__(self,image_shape):\n",
    "    super(DiffNet,self).__init__()\n",
    "\n",
    "    self.ExtractNet = FeatureExtractNet(image_shape)\n",
    "\n",
    "    self.diff = torch.nn.Linear(1,1)\n",
    "    self.sigm = torch.nn.Sigmoid()\n",
    "\n",
    "    self.EuDist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "    #x_1 and x_2 are input pictures\n",
    "  def forward(self,x_1,x_2):\n",
    "\n",
    "    feat_1 = self.ExtractNet(x_1) #predicted features for input 1\n",
    "    feat_2 = self.ExtractNet(x_2) #predicted features for input 2\n",
    "    \n",
    "    #Euclidean distance reshaped to be one-dimensional\n",
    "    diff = self.EuDist(feat_1,feat_2)/feat_1.shape[1]\n",
    "    diff = diff.reshape(-1,1) \n",
    "\n",
    "    \n",
    "    out = self.diff(diff) # computes out = w*d+b from linear layer\n",
    "    out = self.sigm(out) # probability distribution\n",
    "\n",
    "    return out,diff #probability distribution and feature distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c5cfc",
   "metadata": {},
   "source": [
    "#### Define the Loss and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402366e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, euclidean_distance, label):\n",
    "        # euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        pos = (label) * torch.pow(euclidean_distance, 2)\n",
    "        neg = (1-label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        loss_contrastive = torch.mean( pos + neg )\n",
    "        return loss_contrastive\n",
    "\n",
    "def TrainNet(Net,Data_train,Data_test,lr=1e-03,Epochs = 100):\n",
    "\n",
    "    BCE_loss_function = nn.BCELoss()\n",
    "    C_loss_function = ContrastiveLoss()\n",
    "    optimizer = torch.optim.Adam(Net.parameters(), lr=lr)  \n",
    "\n",
    "    N_batches = len(Data_train)\n",
    "\n",
    "    for epoch in tqdm(range(1,Epochs)):\n",
    "      loss_batch = 0\n",
    "      accuracy = 0\n",
    "      n_batch = 0\n",
    "      str = \"\"\n",
    "      for x1,x2,y in Data_train:\n",
    "        prob_pred,diff = Net(x1,x2)\n",
    "          \n",
    "        BCE_loss = BCE_loss_function(prob_pred,y)\n",
    "        loss_Contr = C_loss_function(diff,y)\n",
    "\n",
    "        loss = loss_Contr+0.1*BCE_loss\n",
    "\n",
    "        loss_batch = loss_batch + loss.item()\n",
    "\n",
    "        y_pred = torch.where(prob_pred >= 0.5,1,0)\n",
    "\n",
    "        accuracy = accuracy+(y_pred==y).sum().item()/y.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        n_batch = n_batch+1\n",
    "\n",
    "      loss_batch = loss_batch/N_batches\n",
    "      accuracy_train = accuracy/len(Data_train)\n",
    "      \n",
    "\n",
    "      #Validation accuracy:\n",
    "      loss_test = 0\n",
    "      accuracy = 0\n",
    "      for x1,x2,y in Data_test:\n",
    "        with torch.no_grad(): \n",
    "          Net_eval = Net.eval()       \n",
    "          prob_pred,diff = Net_eval(x1,x2)\n",
    "\n",
    "        # loss = loss_function(y_pred,y)\n",
    "        loss = C_loss_function(diff,y)\n",
    "        # loss = ContrastiveLoss(diff,y)\n",
    "\n",
    "        y_pred = torch.where(prob_pred >= 0.5,1,0)\n",
    "        accuracy = accuracy+(y_pred==y).sum().item()/y.shape[0]\n",
    "\n",
    "        loss_test = loss_test+loss.item()\n",
    "\n",
    "      loss_test = loss_test/len(Data_test)\n",
    "      accuracy = accuracy/len(Data_test)\n",
    "\n",
    "      print(\"*********\")\n",
    "      print(\"epoch: \",epoch,\" loss train: \",loss_batch,\" accuracy train \",accuracy_train,\" loss test\",loss_test,\" accuracy test\",accuracy)\n",
    "\n",
    "    return Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24961a31",
   "metadata": {},
   "source": [
    "#### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = DiffNet(img_size)\n",
    "Net.to(cuda0)\n",
    "\n",
    "Net = TrainNet(Net,Data_train,Data_test,lr=1e-03,Epochs = 150)\n",
    "\n",
    "# torch.save(Net, \"SiameseNet_FaceRec.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4e1e7",
   "metadata": {},
   "source": [
    "#### Test on Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test results on train data\n",
    "Images_1,Images_2,Labels = Data_train[1]\n",
    "idxs = np.random.choice(Images_1.shape[0], size=10)\n",
    "\n",
    "# Net = torch.load(\"SiameseNet_FaceRec.pth\")\n",
    "\n",
    "# Net = Net.cpu()\n",
    "Net_eval = Net.eval() \n",
    "\n",
    "accuracy = 0\n",
    "for idx in idxs:\n",
    "  print(\"************************************\")\n",
    "  with torch.no_grad():\n",
    "    Img_1 = Images_1[idx]\n",
    "    Img_2 = Images_2[idx]\n",
    "    label = Labels[idx]  \n",
    "    \n",
    "    proba_pred,diff = Net_eval(Img_1.reshape(1,Img_1.shape[0],Img_1.shape[1],Img_1.shape[2]),Img_2.reshape(1,Img_1.shape[0],Img_1.shape[1],Img_1.shape[2]))\n",
    "\n",
    "  Img_1 = Img_1.cpu().numpy()\n",
    "  Img_2 = Img_2.cpu().numpy()\n",
    "  label = label.cpu().numpy()\n",
    "  proba_pred = proba_pred.cpu().numpy()[0]\n",
    "\n",
    "  Img_1 = np.transpose(Img_1, (1, 2, 0))\n",
    "  Img_2 = np.transpose(Img_2, (1, 2, 0))\n",
    "\n",
    "  Img_1 =  Img_1.astype(np.uint8)\n",
    "  Img_2 =  Img_2.astype(np.uint8)\n",
    "\n",
    "  print(Img_1.shape)\n",
    "\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "  ax1.imshow(cv.cvtColor(Img_1, cv.COLOR_BGR2RGB))\n",
    "  ax2.imshow(cv.cvtColor(Img_2, cv.COLOR_BGR2RGB))\n",
    "\n",
    "  plt.show()\n",
    "  print(\" similarity \",proba_pred, \" truth\", label)\n",
    "\n",
    "  if proba_pred >= 0.5:\n",
    "    label_pred = 1\n",
    "  else:\n",
    "    label_pred = 0\n",
    "\n",
    "  accuracy = accuracy+(label_pred==label).sum()\n",
    "\n",
    "accuracy = accuracy/len(idxs)\n",
    "print(\"Average accurcay\", accuracy)\n",
    "\n",
    "#-------------------------------------------------------------#\n",
    "\n",
    "#test results on train data\n",
    "Images_1,Images_2,Labels = Data_test[0]\n",
    "idxs = np.random.choice(Images_1.shape[0], size=min(Images_1.shape[0],200))\n",
    "\n",
    "# Net = Net.cpu()\n",
    "Net_eval = Net.eval() \n",
    "\n",
    "accuracy = 0\n",
    "for idx in idxs:\n",
    "  print(\"************************************\")\n",
    "  with torch.no_grad():\n",
    "    Img_1 = Images_1[idx]\n",
    "    Img_2 = Images_2[idx]\n",
    "    label = Labels[idx]  \n",
    "    \n",
    "    proba_pred,diff = Net_eval(Img_1.reshape(1,Img_1.shape[0],Img_1.shape[1],Img_1.shape[2]),Img_2.reshape(1,Img_1.shape[0],Img_1.shape[1],Img_1.shape[2]))\n",
    "\n",
    "  Img_1 = Img_1.cpu().numpy()\n",
    "  Img_2 = Img_2.cpu().numpy()\n",
    "  label = label.cpu().numpy()\n",
    "  proba_pred = proba_pred.cpu().numpy()\n",
    "  proba_pred = proba_pred[0]\n",
    "\n",
    "  Img_1 = np.transpose(Img_1, (1, 2, 0))\n",
    "  Img_2 = np.transpose(Img_2, (1, 2, 0))\n",
    "\n",
    "  Img_1 =  Img_1.astype(np.uint8)\n",
    "  Img_2 =  Img_2.astype(np.uint8)\n",
    "\n",
    "  print(Img_1.shape)\n",
    "\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "  ax1.imshow(cv.cvtColor(Img_1, cv.COLOR_BGR2RGB))\n",
    "  ax2.imshow(cv.cvtColor(Img_2, cv.COLOR_BGR2RGB))\n",
    "\n",
    "  plt.show()\n",
    "  print(\" similarity \",proba_pred, \" truth\", label)\n",
    "\n",
    "  if proba_pred >= 0.5:\n",
    "    label_pred = 1\n",
    "  else:\n",
    "    label_pred = 0\n",
    "\n",
    "  accuracy = accuracy+(label_pred==label).sum()\n",
    "\n",
    "accuracy = accuracy/len(idxs)\n",
    "print(\"Average accurcay\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
